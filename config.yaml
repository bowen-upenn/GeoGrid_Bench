models:
    llm: "gpt-4o"
inference:
    verbose: False
    output_dir: 'output/'
    save_output_response: True
    output_file_name: 'conversation'