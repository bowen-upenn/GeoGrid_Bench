models:
    llm: "gpt-4o"
inference:
    verbose: False
    num_samples: -1
    output_dir: 'output/'
    save_output_response: True